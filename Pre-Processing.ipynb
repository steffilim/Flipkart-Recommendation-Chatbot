{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Datasets\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will be pre-processing the datasets that we will be using for the project. We will be using the following datasets:\n",
    "1. flipkart_com-ecommerce_updated.csv\n",
    "\n",
    "## Summary\n",
    "Summary of Data Cleaning Process of FlipKart Dataset:\n",
    "1. Changed Nan values in 'brand'to 'Unbranded'\n",
    "2. removing rows with null values in `product_specifications` and `description`\n",
    "3. Removing rows that has no `retail_price`, `discounted_price`, or `image`\n",
    "4. Changing the `product_category_tree` column to a list of the main categories\n",
    "5. Extracting the specifications from the `product_specifications` column\n",
    "6. Removing the colors in the `brand` column (might need a second opinion on whether we should do this for the other columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name              0\n",
       "product_category_tree     0\n",
       "pid                       0\n",
       "retail_price              0\n",
       "discounted_price          0\n",
       "discount                  0\n",
       "description               0\n",
       "overall_rating            0\n",
       "brand                     0\n",
       "product_specifications    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this section of code is used to do basic cleaning of the flipkart dataset. \n",
    "# new dataset is saved as 'flipkart_cleaned.csv'\n",
    "# with the new dataset, another set of synthetic data of orders are generated and saved as 'synthetic_v2.csv'\n",
    "\n",
    "# reading flipkart orders data\n",
    "filepath = 'oldData/flipkart_com-ecommerce_updated.csv'\n",
    "flipkart = pd.read_csv(filepath)\n",
    "\n",
    "# finding for null values\n",
    "flipkart.isnull().sum() # sum of null values in each column\n",
    "\n",
    "# changing column values\n",
    "\n",
    "## change nan values in 'brand' to 'Unbranded'\n",
    "flipkart['brand'] = flipkart['brand'].fillna('Unbranded')\n",
    "\n",
    "## removing rows with null values in 'product_specifications' and 'description'\n",
    "flipkart = flipkart.dropna(subset=['product_specifications', 'description', 'retail_price', 'discounted_price'])\n",
    "\n",
    "## removing unnecessary columns\n",
    "flipkart = flipkart.drop(columns = ['image', 'is_FK_Advantage_product', 'product_url', 'uniq_id'])\n",
    "\n",
    "\n",
    "flipkart.isnull().sum()\n",
    "# at this point there should not be any null values in the dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates based on product id (pid)\n",
    "flipkart = flipkart.drop_duplicates(subset=[\"pid\"]) \n",
    "\n",
    "# changing all values to lowercase\n",
    "flipkart = flipkart.apply(lambda col: col.str.lower() if col.dtypes == 'object' else col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the product specifications are in the form of a dictionary, we will be defining a function to extract the specifications, removing any unnecessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing product specifications\n",
    "import re\n",
    "\n",
    "def extract_specs(specs):\n",
    "    pairs = re.findall(r'\"key\"=>\"(.*?)\", \"value\"=>\"(.*?)\"', specs)\n",
    "    pairs_format = [f\"{key}: {value}\" for key, value in pairs]\n",
    "    return ' '.join(pairs_format)\n",
    "\n",
    "# applying the function to the product_specification column, changing all values to lowercase\n",
    "flipkart['product_specifications'] = flipkart['product_specifications'].apply(extract_specs)\n",
    "flipkart.head()\n",
    "\n",
    "def remove_colors(brand):\n",
    "    colors = [\n",
    "        'red', 'green', 'blue', 'yellow', 'black', 'white', 'gray', 'cyan', 'magenta',\n",
    "        'purple', 'pink', 'orange', 'brown', 'beige', 'maroon', 'navy', 'lime', 'olive',\n",
    "        'chocolate', 'teal', 'silver', 'gold', 'azure', 'ivory', 'lavender', 'violet',\n",
    "        'indigo', 'coral', 'salmon', 'khaki', 'orchid', 'turquoise', 'sienna', 'plum',\n",
    "        'tan', 'fuchsia', 'burgundy', 'chartreuse', 'emerald', 'amethyst', 'ruby', \n",
    "        'sapphire', 'mint', 'peach', 'lime green', 'mustard', 'ochre', 'aquamarine', \n",
    "        'bisque', 'cadetblue', 'cornflowerblue', 'darkgoldenrod', 'darkolivegreen', \n",
    "        'darkorchid', 'deeppink', 'deepskyblue', 'dodgerblue', 'firebrick', 'forestgreen', \n",
    "        'gainsboro', 'ghostwhite', 'goldenrod', 'green yellow', 'honeydew', 'hotpink', \n",
    "        'indianred', 'ivory', 'khaki', 'lavender blush', 'lemon chiffon', 'light blue', \n",
    "        'light coral', 'light cyan', 'light goldenrod yellow', 'light green', 'light pink', \n",
    "        'light salmon', 'light sea green', 'light sky blue', 'light slate gray', \n",
    "        'light steel blue', 'light yellow', 'limegreen', 'linen', 'medium aquamarine', \n",
    "        'medium blue', 'medium orchid', 'medium purple', 'medium sea green', \n",
    "        'medium slate blue', 'medium spring green', 'medium turquoise', 'medium violet red', \n",
    "        'midnight blue', 'mint cream', 'misty rose', 'moccasin', 'navajo white', 'old lace', \n",
    "        'olive drab', 'orange red', 'orchid', 'pale goldenrod', 'pale green', 'pale turquoise', \n",
    "        'pale violet red', 'papaya whip', 'peach puff', 'peru', 'pink', 'plum', 'powder blue', \n",
    "        'rosy brown', 'royal blue', 'saddle brown', 'salmon', 'sandy brown', \n",
    "        'sea green', 'seashell', 'sienna', 'sky blue', 'slate blue', 'slate gray', \n",
    "        'snow', 'spring green', 'steel blue', 'tan', 'thistle', 'tomato', 'turquoise', \n",
    "        'violet', 'wheat', 'white smoke', 'yellow green', 'crimson', 'alice blue', \n",
    "        'antique white', 'aqua', 'aquamarine', 'blanched almond', 'blue violet', 'burlywood', \n",
    "        'cadet blue', 'chartreuse', 'chocolate', 'coral', 'cornflower blue', 'crimson', \n",
    "        'cyan', 'dark blue', 'dark cyan', 'dark grey', 'dark green', 'dark khaki', \n",
    "        'dark magenta', 'dark olive green', 'dark orange', 'dark orchid', 'dark red', \n",
    "        'dark salmon', 'dark sea green', 'dark slate blue', 'dark slate gray', 'dark turquoise', \n",
    "        'dark violet', 'deep pink', 'deep sky blue', 'dim gray', 'dim grey', 'dodger blue', \n",
    "        'firebrick', 'floral white', 'forest green', 'fuchsia', 'gainsboro', 'ghost white', \n",
    "        'gold', 'goldenrod', 'gray', 'green', 'green yellow', 'grey', 'honeydew', 'hot pink', \n",
    "        'indian red', 'indigo', 'ivory', 'khaki', 'lavender', 'lavender blush', 'lawn green', \n",
    "        'lemon chiffon', 'light blue', 'light coral', 'light cyan', 'light golden rod yellow', \n",
    "        'light gray', 'light grey', 'light green', 'light pink', 'light salmon', \n",
    "        'light sea green', 'light sky blue', 'light slate gray', 'light slate grey', \n",
    "        'light steel blue', 'light yellow', 'lime', 'lime green', 'linen', 'magenta', \n",
    "        'maroon', 'medium aquamarine', 'medium blue', 'medium orchid', 'medium purple', \n",
    "        'medium sea green', 'medium slate blue', 'medium spring green', 'medium turquoise', \n",
    "        'medium violet red', 'midnight blue', 'mint cream', 'misty rose', 'moccasin', \n",
    "        'navajo white', 'navy', 'old lace', 'olive', 'olive drab', 'orange', 'orange red', \n",
    "        'orchid', 'pale golden rod', 'pale green', 'pale turquoise', 'pale violet red', \n",
    "        'papaya whip', 'peach puff', 'peru', 'pink'\n",
    "    ]\n",
    "\n",
    "    color_pattern = r'\\b(' + '|'.join(colors) + r')\\b'\n",
    "    brand = re.sub(color_pattern, '', brand, flags=re.IGNORECASE).strip()\n",
    "    return brand\n",
    "\n",
    "flipkart['brand'] = flipkart['brand'].apply(remove_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are unnecessary values in the `product_category_tree` column, we will be extracting the main information from the column and storing it in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the 'product_category_tree' column\n",
    "\n",
    "flipkart['product_category_tree'] = flipkart['product_category_tree'].map(lambda x:x.strip('[]'))\n",
    "flipkart['product_category_tree'] = flipkart['product_category_tree'].map(lambda x:x.strip('\"\"'))\n",
    "flipkart['product_category_tree'] = flipkart['product_category_tree'].map(lambda x:x.split('>>'))\n",
    "\n",
    "def clean_list(categories):\n",
    "    cleaned_categories = [category.strip().replace('\"', \"'\") for category in categories]\n",
    "    return cleaned_categories\n",
    "\n",
    "flipkart['product_category_tree'] = flipkart['product_category_tree'].apply(clean_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flipkart['product_category_tree'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As the Synthetic Dataset is based off the FlipKart Dataset, we will be using the cleaned version of the FlipKart Dataset for the Synthetic Dataset.\n",
    "The new datasets can be found in the newData Folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data\n",
    "flipkart.to_csv('newData/flipkart_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
